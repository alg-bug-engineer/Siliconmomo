import asyncio
import argparse
import json
import os
from pathlib import Path
from datetime import datetime
from config.settings import BASE_URL, DEEP_RESEARCH_ENABLED, DEEP_RESEARCH_OUTPUT_DIR, DEEP_RESEARCH_LLM_MODEL
from core.recorder import SessionRecorder
from core.llm_client import LLMClient
from core.researcher import ResearchAgent


async def generate_report_from_file(json_file_path: str, recorder: SessionRecorder):
    """
    ä»å·²æœ‰çš„ JSON æ•°æ®æ–‡ä»¶ç›´æ¥ç”Ÿæˆæ·±åº¦è°ƒç ”æŠ¥å‘Š
    
    Args:
        json_file_path: JSON æ•°æ®æ–‡ä»¶è·¯å¾„
        recorder: ä¼šè¯è®°å½•å™¨
    """
    if not DEEP_RESEARCH_ENABLED:
        print("Deep research mode is disabled in config/settings.py. Please enable it to run this workflow.")
        return
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    json_path = Path(json_file_path)
    if not json_path.exists():
        recorder.log("error", f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        return
    
    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    if not json_path.suffix.lower() == '.json':
        recorder.log("error", f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {json_path.suffix}ï¼Œè¯·æä¾› .json æ–‡ä»¶")
        return
    
    recorder.log("info", f"ğŸ“‚ [æŠ¥å‘Šç”Ÿæˆ] ä»æ–‡ä»¶åŠ è½½æ•°æ®: {json_file_path}")
    
    # åŠ è½½ JSON æ•°æ®
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            research_data = json.load(f)
        
        if not isinstance(research_data, list):
            recorder.log("error", "âŒ æ•°æ®æ ¼å¼é”™è¯¯: æœŸæœ› JSON æ•°ç»„æ ¼å¼")
            return
        
        if len(research_data) == 0:
            recorder.log("error", "âŒ æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return
        
        recorder.log("info", f"âœ… [æŠ¥å‘Šç”Ÿæˆ] æˆåŠŸåŠ è½½ {len(research_data)} æ¡å¸–å­æ•°æ®")
        
    except json.JSONDecodeError as e:
        recorder.log("error", f"âŒ JSON è§£æå¤±è´¥: {e}")
        return
    except Exception as e:
        recorder.log("error", f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    llm_client = LLMClient(recorder)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = DEEP_RESEARCH_OUTPUT_DIR / datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir.mkdir(parents=True, exist_ok=True)
    recorder.log("info", f"ğŸ“‚ [æŠ¥å‘Šç”Ÿæˆ] è¾“å‡ºç›®å½•: {output_dir}")
    
    # ä»æ–‡ä»¶åæå–å…³é”®è¯
    keyword = json_path.stem.replace('research_data_', '')
    recorder.log("info", f"ğŸ·ï¸ [æŠ¥å‘Šç”Ÿæˆ] ç ”ç©¶ä¸»é¢˜: {keyword}")
    
    # åˆ›å»º ResearchAgent å®ä¾‹ï¼ˆç”¨äºè°ƒç”¨æŠ¥å‘Šç”Ÿæˆæ–¹æ³•ï¼‰
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„ BrowserManager æ¥ç»•è¿‡åˆå§‹åŒ–æ£€æŸ¥
    class MockBrowserManager:
        def __init__(self):
            self.page = None
    
    mock_bm = MockBrowserManager()
    research_agent = ResearchAgent(mock_bm, llm_client, recorder)
    
    # æ‰‹åŠ¨è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆè¦†ç›–é»˜è®¤çš„æ—¶é—´æˆ³ç›®å½•ï¼‰
    research_agent.output_dir = output_dir
    
    # ç”ŸæˆæŠ¥å‘Š
    try:
        recorder.log("info", "ğŸ§  [æŠ¥å‘Šç”Ÿæˆ] æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆè°ƒç ”æŠ¥å‘Š...")
        report = await research_agent._generate_report(research_data)
        
        # ä¿å­˜æŠ¥å‘Š
        await research_agent._save_report(report, keyword)
        
        recorder.log("success", f"âœ… [æŠ¥å‘Šç”Ÿæˆ] æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_dir}")
        
    except Exception as e:
        recorder.log("error", f"âŒ [æŠ¥å‘Šç”Ÿæˆ] ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
        raise


async def main():
    parser = argparse.ArgumentParser(description="Run deep research workflow.")
    parser.add_argument("keyword_or_file", type=str, help="å…³é”®è¯æˆ– JSON æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .json æ–‡ä»¶ç›´æ¥ç”ŸæˆæŠ¥å‘Šï¼‰")
    args = parser.parse_args()

    if not DEEP_RESEARCH_ENABLED:
        print("Deep research mode is disabled in config/settings.py. Please enable it to run this workflow.")
        return

    # åˆ¤æ–­å‚æ•°æ˜¯æ–‡ä»¶è·¯å¾„è¿˜æ˜¯å…³é”®è¯
    input_path = Path(args.keyword_or_file)
    
    # å¦‚æœæ˜¯å­˜åœ¨çš„ .json æ–‡ä»¶ï¼Œç›´æ¥è¿›å…¥æŠ¥å‘Šç”Ÿæˆæ¨¡å¼
    if input_path.exists() and input_path.suffix.lower() == '.json':
        recorder = SessionRecorder()
        try:
            await generate_report_from_file(str(input_path), recorder)
        except Exception as e:
            recorder.log("error", f"âŒ [æŠ¥å‘Šç”Ÿæˆ] å·¥ä½œæµå¤±è´¥: {e}")
        finally:
            recorder.save_report()
        return

    # å¦åˆ™ï¼ŒæŒ‰ç…§åŸæ¥çš„å…³é”®è¯æ¨¡å¼è¿è¡Œï¼ˆéœ€è¦æµè§ˆå™¨ï¼‰
    from core.browser_manager import BrowserManager
    from core.human_motion import HumanMotion
    from actions.interaction import ActionExecutor
    from core.supervisor import Supervisor

    recorder = SessionRecorder()
    bm = BrowserManager()
    
    try:
        await bm.start()
        
        # Ensure we are on a valid page (e.g., base URL) before starting operations
        if "xiaohongshu.com" not in bm.page.url:
            await bm.page.goto(BASE_URL)
            await asyncio.sleep(2)  # Give some time to load

        human = HumanMotion(bm.page)
        llm_client = LLMClient(recorder)
        
        # ActionExecutor is needed to satisfy Supervisor's constructor,
        # but its main cycle won't be run in this script.
        # Its KB might still be relevant if deep research uses it.
        worker = ActionExecutor(bm.page, human, recorder, llm_client) 
        
        director = Supervisor(bm, human, worker, recorder, llm_client, max_duration=300)  # Set a reasonable max_duration
        
        # Trigger the deep research workflow
        await director.start_deep_research_workflow(args.keyword_or_file)

    except KeyboardInterrupt:
        recorder.log("warning", "ç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­")
    finally:
        # worker.kb.force_flush() # Only if KB was used and needs flushing
        recorder.save_report()
        await bm.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
