import json
import random
from zai import ZhipuAiClient  # æ›´æ–° SDK å¼•å…¥
from config.settings import ZHIPU_AI_KEY, LLM_MODEL, TARGET_TOPICS

class LLMClient:
    def __init__(self, recorder):
        # åˆå§‹åŒ–æ–°çš„ Client
        self.client = ZhipuAiClient(api_key=ZHIPU_AI_KEY)
        self.recorder = recorder

    def analyze_and_comment(self, title, content):
        """
        åˆ†æå¸–å­å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦ç›¸å…³ï¼Œå¹¶ç”Ÿæˆè¯„è®º
        """
        # æ„é€  Prompt - AI æ‚è´§åº—ä¸»å®šä½
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªæ´»è·ƒåœ¨å°çº¢ä¹¦çš„ AI æ‚è´§åº—åšä¸»"Momo"ï¼Œä½ çš„ä¸“å®¶äººè®¾æ˜¯ï¼šä¸“æ³¨äºæ¨èå„ç±» AI å·¥å…·ã€æµè§ˆå™¨æ’ä»¶ã€æ•ˆç‡ç¥å™¨çš„åšä¸»ã€‚

        ã€ä»»åŠ¡ç›®æ ‡ã€‘
        åˆ†æç»™å®šçš„å¸–å­å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦å€¼å¾—äº’åŠ¨å’Œæ”¶è—ä½œä¸ºç´ æï¼Œå¦‚æœå€¼å¾—ï¼Œç”Ÿæˆä¸€æ¡çœŸå®çš„ã€å£è¯­åŒ–çš„è¯„è®ºã€‚

        ã€åˆ¤æ–­æ ‡å‡†ã€‘
        1. å¸–å­å¿…é¡»å±äºä»¥ä¸‹é¢†åŸŸä¹‹ä¸€ï¼š{", ".join(TARGET_TOPICS)}ã€‚å¦‚æœå¸–å­æ˜¯æ— å…³çš„ï¼ˆå¦‚æƒ…æ„Ÿã€ç©¿æ­ã€å¨±ä¹ã€æ¸¸æˆï¼‰ï¼Œè¯·æ ‡è®°ä¸ºä¸ç›¸å…³ã€‚
        2. å¦‚æœå¸–å­æ­£æ–‡æ–‡å­—å¤ªå°‘ï¼ˆå°‘äº10ä¸ªå­—ï¼‰ï¼Œæˆ–è€…æ˜¯çº¯å›¾ç‰‡æ— æ„ä¹‰å†…å®¹ï¼Œè¯·æ ‡è®°ä¸ºä¸éœ€è¦è¯„è®ºã€‚
        3. **é«˜è´¨é‡æ ‡å‡†**ï¼šæ–‡æ¡ˆæœ‰å®ç”¨ä»·å€¼ã€ä¿¡æ¯æ¸…æ™°ã€æœ‰æ¨èæ„ä¹‰ã€é€‚åˆä»¿å†™åˆ›ä½œã€‚åªæœ‰åŒæ—¶æ»¡è¶³ä»¥ä¸‹æ¡ä»¶çš„æ‰ç®—é«˜è´¨é‡ï¼š
           - æ–‡æ¡ˆæœ‰æ˜ç¡®çš„å†…å®¹ç±»å‹ï¼ˆå·¥å…·æ¨è/åŠŸèƒ½ä»‹ç»/ä½¿ç”¨æ•™ç¨‹/é¿å‘æŒ‡å—/åˆé›†æ¨èï¼‰
           - æœ‰å®ç”¨ä»·å€¼ï¼Œèƒ½æä¾›å·¥å…·æˆ–æ•ˆç‡æå‡ä¿¡æ¯
           - ç»“æ„æ¸…æ™°ï¼Œé€‚åˆä½œä¸ºåˆ›ä½œå‚è€ƒ
           - å­—æ•°é€‚ä¸­ï¼ˆ50-500å­—ï¼‰

        ã€å¸–å­ä¿¡æ¯ã€‘
        æ ‡é¢˜ï¼š{title}
        æ­£æ–‡ï¼š{content}

        ã€è¾“å‡ºè¦æ±‚ã€‘
        è¯·ä»…è¿”å›ä¸€ä¸ªæ ‡å‡†çš„ JSON æ ¼å¼å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ï¼š
        {{
            "is_relevant": true/false,
            "is_high_quality": true/false,  // æ˜¯å¦é«˜è´¨é‡ç´ æï¼ˆç”¨äºåç»­åˆ›ä½œå‚è€ƒï¼‰
            "should_comment": true/false,
            "comment_text": "ä½ çš„è¯„è®ºå†…å®¹", // 50å­—ä»¥å†…ï¼Œå£è¯­åŒ–ï¼Œä¸è¦å¸¦å¼•å·
            "style_hint": "å·¥å…·æ¨è/åŠŸèƒ½ä»‹ç»/ä½¿ç”¨æ•™ç¨‹/é¿å‘æŒ‡å—/åˆé›†æ¨è" // å†…å®¹ç±»å‹æç¤ºï¼Œç”¨äºåç»­åˆ›ä½œå‚è€ƒ
        }}
        """

        try:
            # ä½¿ç”¨æ–°çš„è°ƒç”¨æ–¹å¼
            response = self.client.chat.completions.create(
                model=LLM_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼éµå¾ªJSONè¾“å‡ºæ ¼å¼çš„AIåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                # å¦‚æœéœ€è¦å¯ç”¨æ·±åº¦æ€è€ƒï¼Œå¯ä»¥è§£å¼€ä¸‹é¢æ³¨é‡Šï¼Œä½†ç®€å•ä»»åŠ¡ä¸å»ºè®®å¼€å¯ä»¥èŠ‚çœæ—¶é—´
                # thinking={"type": "enabled"} 
            )
            
            # è·å–ç»“æœ
            result_text = response.choices[0].message.content.strip()
            
            # æ¸…æ´— Markdown æ ‡è®°
            if result_text.startswith("```json"):
                result_text = result_text.split("```json")[1]
            if result_text.endswith("```"):
                result_text = result_text.rsplit("```", 1)[0]
            
            result = json.loads(result_text.strip())
            # ç¡®ä¿è¿”å›æ‰€æœ‰å¿…éœ€å­—æ®µï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
            if "is_high_quality" not in result:
                result["is_high_quality"] = result.get("is_relevant", False)
            if "style_hint" not in result:
                result["style_hint"] = ""
            return result

        except Exception as e:
            self.recorder.log("error", f"ğŸ§  [å¤§è„‘] æ€è€ƒå¤±è´¥: {e}")
            return {
                "is_relevant": False,
                "is_high_quality": False,
                "should_comment": False,
                "comment_text": "",
                "style_hint": ""
            }

    # === è½¯å¹¿è¯„è®ºç”Ÿæˆ ===

    def generate_promo_comment(self, title: str, content: str, product: dict, interaction_type: str = "help_first") -> dict:
        """
        ç”Ÿæˆè½¯å¹¿è¯„è®º
        :param title: å¸–å­æ ‡é¢˜
        :param content: å¸–å­å†…å®¹
        :param product: äº§å“å¯¹è±¡
        :param interaction_type: äº’åŠ¨ç±»å‹ï¼ˆhelp_first/value_share/direct_promoï¼‰
        :return: è¯„è®ºç»“æœå­—å…¸
        """
        product_name = product.get("name", "")
        product_tagline = product.get("tagline", "")
        product_category = product.get("category", "")

        # æ ¹æ®äº’åŠ¨ç±»å‹è°ƒæ•´ç­–ç•¥
        if interaction_type == "help_first":
            strategy_desc = "å…ˆæä¾›å¸®åŠ©å’Œè§£å†³æ–¹æ¡ˆï¼Œç„¶åè‡ªç„¶åœ°æåŠäº§å“ä½œä¸ºæ›´é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆ"
            tone_desc = "çƒ­å¿ƒåŠ©äººã€çœŸè¯šåˆ†äº«"
        elif interaction_type == "value_share":
            strategy_desc = "åˆ†äº«è‡ªå·±çš„ä½¿ç”¨ç»éªŒå’Œå¿ƒå¾—ï¼Œåœ¨åˆé€‚çš„æ—¶å€™æåŠä½¿ç”¨è¿‡çš„å·¥å…·"
            tone_desc = "ç»éªŒåˆ†äº«ã€çœŸè¯šäº¤æµ"
        else:  # direct_promo
            strategy_desc = "ç›´æ¥ä½†å…‹åˆ¶åœ°æ¨èäº§å“ï¼Œå¼ºè°ƒå®ƒæ­£å¥½èƒ½è§£å†³å¸–å­ä¸­çš„é—®é¢˜"
            tone_desc = "ç›´æ¥æ¨èã€è§£å†³é—®é¢˜"

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ´»è·ƒåœ¨å°çº¢ä¹¦çš„ AI æ‚è´§åº—åšä¸»"Momo"ï¼Œä½ æœ‰ä¸€æ¬¾äº§å“ï¼š{product_name}ï¼ˆ{product_tagline}ï¼‰ã€‚

ã€ä»»åŠ¡ç›®æ ‡ã€‘
é’ˆå¯¹ä¸‹é¢çš„å¸–å­ï¼Œç”Ÿæˆä¸€æ¡è½¯å¹¿è¯„è®ºã€‚ä¸è¦æ˜æ˜¾åƒå¹¿å‘Šï¼Œè¦åƒçœŸå®çš„ç”¨æˆ·äº¤æµã€‚

ã€å¸–å­ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{title}
æ­£æ–‡ï¼š{content[:500]}

ã€ä½ çš„äº§å“ã€‘
åç§°ï¼š{product_name}
å–ç‚¹ï¼š{product_tagline}
åˆ†ç±»ï¼š{product_category}

ã€è¯„è®ºç­–ç•¥ã€‘
{strategy_desc}

ã€è¦æ±‚ã€‘
1. **è¯­æ°”**ï¼š{tone_desc}ï¼ŒåƒçœŸäººåšä¸»åœ¨èŠå¤©
2. **å¼€å¤´**ï¼šå…ˆå›åº”å¸–å­çš„å†…å®¹æˆ–é—®é¢˜ï¼Œè¡¨ç¤ºç†è§£
3. **äº§å“æåŠ**ï¼š
   - help_firstï¼šå›ç­”é—®é¢˜ â†’ é¡ºå¸¦è¯´"æˆ‘ç”¨è¿‡ä¸€ä¸ªå·¥å…·èƒ½ç®€åŒ–è¿™ä¸ª"
   - value_shareï¼šåˆ†äº«ç»å† â†’ æåŠ"æˆ‘ç”¨XXå·¥å…·ï¼Œæ•ˆç‡æå‡ä¸å°‘"
   - direct_promoï¼šè¯´æ˜äº§å“æ­£å¥½è§£å†³è¿™ä¸ªé—®é¢˜
4. **è‡ªç„¶åº¦**ï¼šä¸è¦å †ç Œäº§å“ä¿¡æ¯ï¼Œä¸è¦é¢‘ç¹é‡å¤äº§å“å
5. **é•¿åº¦**ï¼š30-80å­—
6. **Emoji**ï¼šé€‚å½“ä½¿ç”¨ 1-2 ä¸ªï¼ˆğŸš€ğŸ’¡âœ¨ç­‰ï¼‰

ã€é¿å…ã€‘
- ä¸è¦åƒç¡¬å¹¿ä¸€æ ·ç½—åˆ—åŠŸèƒ½
- ä¸è¦è¿‡åˆ†å¼ºè°ƒä»·æ ¼æˆ–è´­ä¹°é“¾æ¥
- ä¸è¦å¤¸å¤§æ•ˆæœ

ã€è¾“å‡ºæ ¼å¼ (JSON Only)ã€‘
{{
    "comment_text": "è¯„è®ºå†…å®¹...",
    "is_natural": true,  // è¯„è®ºæ˜¯å¦è‡ªç„¶ä¸è¿‡åˆ†åƒå¹¿å‘Š
    "product_mentioned": true  // æ˜¯å¦æåˆ°äº†äº§å“
}}
"""

        try:
            response = self.client.chat.completions.create(
                model=LLM_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿è½¯æ€§æ¨å¹¿çš„å°çº¢ä¹¦åšä¸»ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8
            )

            result_text = response.choices[0].message.content.strip()

            # æ¸…æ´— Markdown
            if result_text.startswith("```json"):
                result_text = result_text.split("```json")[1]
            if result_text.endswith("```"):
                result_text = result_text.rsplit("```", 1)[0]

            result = json.loads(result_text.strip())

            # æ·»åŠ é¢å¤–ä¿¡æ¯
            result["interaction_type"] = interaction_type
            result["product_id"] = product.get("id")

            self.recorder.log("info", f"ğŸ§  [è½¯å¹¿è¯„è®º] ç”Ÿæˆå®Œæˆ: {result.get('comment_text', '')[:30]}...")
            return result

        except Exception as e:
            self.recorder.log("error", f"ğŸ§  [è½¯å¹¿è¯„è®º] ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›ç®€å•çš„å…œåº•è¯„è®º
            fallback_comments = [
                f"è¿™ä¸ªé—®é¢˜æˆ‘ä¹Ÿé‡åˆ°è¿‡ï¼Œåæ¥ç”¨ä¸€ä¸ªå·¥å…·èƒ½ä¸€é”®å¤„ç†ï¼Œçœäº‹å¤šäº† ğŸš€",
                f"æ¨èè¯•è¯•æˆ‘ç”¨çš„è¿™ä¸ªï¼Œæ•ˆç‡æå‡å¾ˆæ˜æ˜¾ ğŸ’¡",
                f"æˆ‘ä¹‹å‰ä¹Ÿæ‰‹åŠ¨æè¿‡ï¼Œåæ¥å‘ç°{product_name}èƒ½è‡ªåŠ¨å¤„ç† âœ¨"
            ]
            return {
                "comment_text": random.choice(fallback_comments),
                "is_natural": True,
                "product_mentioned": True,
                "interaction_type": interaction_type,
                "product_id": product.get("id")
            }

        return None

    async def generate_text(self, prompt: str, model: str = LLM_MODEL) -> str:
        """
        ç”Ÿæˆé€šç”¨æ–‡æœ¬å“åº”ã€‚
        :param prompt: æ–‡æœ¬ç”Ÿæˆæç¤ºè¯ã€‚
        :param model: ä½¿ç”¨çš„ LLM æ¨¡å‹åç§°ã€‚
        :return: ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹ã€‚
        """
        messages = [
            {"role": "user", "content": prompt}
        ]
        try:
            # ZhipuAiClient ä½¿ç”¨åŒæ­¥è°ƒç”¨ï¼Œä¸éœ€è¦ await
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            self.recorder.log("error", f"ğŸ§  [LLMæ–‡æœ¬ç”Ÿæˆ] è°ƒç”¨ LLM å¤±è´¥ (æ¨¡å‹: {model}): {e}")
            return f"Error: LLM failed to generate text for model {model}."
